{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156d5f9a-250c-401f-8ee3-882253b31d8a",
   "metadata": {},
   "source": [
    "Langchain helps us use LLMs in more advanced ways.  \n",
    "It provides us tools to set up workflows for LLMs based activities like chatbots, QA systems, text summarization etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf38e3f-4c37-4589-9e53-dde0b122ed2a",
   "metadata": {},
   "source": [
    "1. Chains - These are helpful in setting up a pipeline which involves multiple activities. Chains helps us setting up these actions in sequence.\n",
    "\n",
    "2. Prompt template - It provide tool to create custom prompt template which uses placeholders, and can be very helpful in creating prompts dynamically.\n",
    "\n",
    "\n",
    "3. Agents - These provides LLMs extra capacity to access/perform some tasks. These provides access to APIs, databases etc\n",
    "\n",
    "4. Memory - Langchain also provides buffer memory which helps model remember previous chats and continue the text generation relative to previous interactions\n",
    "\n",
    "5. Tool integration - helps LLMs interact with other tools like APIS and databases.\n",
    "\n",
    "6. RAG - It provides tools for retrieving some information and store it in database before generating response\n",
    "\n",
    "7. Document loader and Vector database  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfff833-6e17-410f-a31e-242fe1a70de1",
   "metadata": {},
   "source": [
    "# 1. Chains: Building Modular Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d188fe4-5cb0-4edd-8b95-74ec1cc6f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models  import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e2a3da-0334-4a89-93e7-23ff685b38d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_16956\\1620702558.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n"
     ]
    }
   ],
   "source": [
    "# Defining a prompt template\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['topic'],template=\"Write a detailed explaination about {topic}\")\n",
    "\n",
    "## Initializng the LLMs\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "## Create a chain\n",
    "chain = LLMChain(llm=llm,prompt=prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3cd9b6-701d-4a64-b608-a2f9eac158c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and act like humans. This includes tasks such as problem-solving, learning, planning, speech recognition, and decision making. AI encompasses a wide range of technologies, including machine learning, natural language processing, computer vision, robotics, and expert systems.\n",
      "\n",
      "One of the key components of AI is machine learning, which allows machines to learn from data and improve their performance over time without being explicitly programmed. This is achieved through algorithms and models that analyze and interpret data, identify patterns and trends, and make predictions or decisions based on that information.\n",
      "\n",
      "Natural language processing (NLP) is another important aspect of AI, which enables machines to understand and interact with human language. This technology is used in applications such as speech recognition, chatbots, and language translation.\n",
      "\n",
      "Computer vision is another field of AI that focuses on enabling machines to interpret and understand visual information, such as images and videos. This technology is used in applications such as facial recognition, object detection, and autonomous vehicles.\n",
      "\n",
      "AI is also being used in robotics to create intelligent machines that can perform tasks autonomously, such as industrial automation, self-driving cars, and medical robots.\n",
      "\n",
      "Overall, AI has the potential to revolutionize many industries and improve efficiency, accuracy, and productivity. However, there are also concerns about the ethical implications of AI, such as bias in algorithms, job displacement, and privacy issues. It is important for researchers, policymakers, and developers to work together to ensure that AI is developed and deployed in a responsible and ethical manner.\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "response = chain.run({\"topic\": \"Artificial Intelligence\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba8860-03a0-41d7-8de5-03ee7c9b3328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e1a1ff-118f-49ba-ae94-b35b8f13bf37",
   "metadata": {},
   "source": [
    "# 2. Prompt Templates: Crafting Dynamic Inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e85dbf30-2f64-41fe-aab7-7f5c2bcf31bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Manoj, Happy Birthday! Wishing you a fantastic day ahead..\n"
     ]
    }
   ],
   "source": [
    "## Defining a prompt with Placeholder\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['name','occasion'],\n",
    "    template=\"Dear {name}, Happy {occasion}! Wishing you a fantastic day ahead..\"\n",
    ")\n",
    "\n",
    "## Generate a prompt by filling in the placeholders\n",
    "\n",
    "prompt2 = prompt2.format(name='Manoj',occasion='Birthday')\n",
    "\n",
    "print(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b8268-26d8-4df0-a4ea-8baa82813581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bec0052-a568-4d4f-9535-ba832a12b2c3",
   "metadata": {},
   "source": [
    "# 3. Agents: Dynamic Decision-Making\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bff10775-0894-4426-ae1e-4a009f60a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent,Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f2523c-6c95-4834-8fa5-ab44c6fb5905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_16956\\3385027162.py:12: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. See LangGraph documentation for more details: https://langchain-ai.github.io/langgraph/. Refer here for its pre-built ReAct agent: https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/\n",
      "  agent = initialize_agent(tools=[python_tool],llm=llm,agent=\"zero-shot-react-description\",verbose=True)\n"
     ]
    }
   ],
   "source": [
    "## Initializing Python execution tool\n",
    "\n",
    "python_tool = Tool(\n",
    "    name = \"Python Executor\",\n",
    "    func = PythonREPLTool().run,\n",
    "    description=\"Executes the Python scripts\"\n",
    ")\n",
    "\n",
    "# Initialize the agent with the tool\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\",temperature=0)\n",
    "\n",
    "agent = initialize_agent(tools=[python_tool],llm=llm,agent=\"zero-shot-react-description\",verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59ed696d-5560-4f11-b0e7-f55a923e67e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should run the Python code provided and analyze each line to understand what it does. I should also check for any errors in the code.\n",
      "Action: Python Executor\n",
      "Action Input: \n",
      "'''\n",
      "x = 10\n",
      "y = 20,\n",
      "z = x+y\n",
      "\n",
      "z\n",
      "'''\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe code has a syntax error with an extra comma after the value of y. This will cause an error when trying to add x and y together.\n",
      "Action: Python Executor\n",
      "Action Input: \n",
      "'''\n",
      "x = 10\n",
      "y = 20\n",
      "z = x+y\n",
      "\n",
      "z\n",
      "'''\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe code is now corrected and should run without errors. I will now execute the code to get the output.\n",
      "Action: Python Executor\n",
      "Action Input: \n",
      "'''\n",
      "x = 10\n",
      "y = 20\n",
      "z = x+y\n",
      "\n",
      "z\n",
      "'''\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe code is correct and should output the sum of x and y, which is 30.\n",
      "Final Answer: 30\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "## User provided python code\n",
    "\n",
    "user_code = \"\"\"\n",
    "x = 10\n",
    "y = 20,\n",
    "z = x+y\n",
    "\n",
    "z\n",
    "\"\"\"\n",
    "\n",
    "## Query the agent with the code\n",
    "query = f\"Run the following Python code and provide the output, also explain each line of the code in detail. Also point out for any error in the code : \\n{user_code}\"\n",
    "response = agent.run(query)\n",
    "#Print the output\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d072ca-1b62-43a8-9aec-87355fe7c262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81a052d-5729-40ad-b8be-f710e2c98eac",
   "metadata": {},
   "source": [
    "# 4. Memory: Maintaining Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "685efb51-176b-4b97-bf7c-c12803fb5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a1a1202-fa16-4cdb-9504-1f698e6e48e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_16956\\1332199944.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_16956\\1332199944.py:10: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  chain = ConversationChain(llm=llm,memory=memory)\n"
     ]
    }
   ],
   "source": [
    "## Initializing the memory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Initialize the agent with the tool\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\",temperature=0)\n",
    "\n",
    "## Create a conversational chain\n",
    "\n",
    "chain = ConversationChain(llm=llm,memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b073806-b287-4c5e-90a5-9278121ed208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! The flight from Bengaluru to New York typically takes around 18 to 20 hours, depending on the airline and any layovers. The distance between the two cities is approximately 8,000 miles. Would you like more information about the flight details?\n"
     ]
    }
   ],
   "source": [
    "print(chain.predict(input = \"Hi, How long is the flight from Bengaluru to New York\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eb1a796-eb67-484f-ae27-fb528c8210e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! In New York, there are so many amazing places to visit. Some popular attractions include the Statue of Liberty, Central Park, Times Square, the Empire State Building, Broadway theaters, the Metropolitan Museum of Art, and the One World Observatory. If you're interested in shopping, you can check out Fifth Avenue or SoHo. And don't forget to try some delicious food in the diverse neighborhoods of the city, such as Chinatown, Little Italy, and Harlem. Let me know if you need more recommendations!\n"
     ]
    }
   ],
   "source": [
    "print(chain.predict(input = \"Can you recommend some good places to visit there ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a848e-a95a-4779-ae09-707405779fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3444d24a-54b6-4e5a-8009-e43341d56bab",
   "metadata": {},
   "source": [
    "# 5. Retrieval-Augmented Generation (RAG): Combining Retrieval with Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f510ce60-ef8d-4ba5-b869-044f0918ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "import pinecone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93179013-2432-475b-9be7-f4c30d46bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone instance\n",
    "pc = pinecone.Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# Create or connect to an index\n",
    "index_name = \"langchain-demo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5445102-5b2d-443b-9ed3-ebdad56b2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index (only needs to be done once)\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(index_name, dimension=1536, spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))  # Dimension must match the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60347066-517e-4fac-a184-a520a3a23231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings and Pinecone vectorstore\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectostore = Pinecone.from_texts(\n",
    "        [\"Person xyz won nnn award on October 21st of 2025\", \"When xyz was of 34 years age he married klm.\"\n",
    "        \"klm was 6 years older than her husband\",\"xyz was 87 when he won nnn award\"],\n",
    "        embeddings,\n",
    "        index_name=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8a8a31c-0242-493a-a28c-69dc4a574580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klm is the name of the person who xyz married when he was 34 years old. She was 6 years older than him.\n"
     ]
    }
   ],
   "source": [
    "# Create RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectostore.as_retriever()\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "response = qa.run(\"Who is klm ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8ba32f1-fb39-4bd7-a144-49940140e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since xyz was 87 years old when he won the award, and klm was 6 years older than xyz, klm's age when xyz won the award would be 87 + 6 = 93 years old.\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "response = qa.run(\"What was klm's age when xyz won nnn award ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c3c32-8c26-4d9f-b423-09b0c3a6b28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d34ee-9ee5-429d-b2bb-893d1446d845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd546d7-0b48-4a6a-8f48-7bd1202b5bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17841972-89b6-4be5-a218-85e2c63b73a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a2e526-43b4-4fd4-bdbf-11b68f2a6810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16654f-5a12-451f-b90b-86e194bf3a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4391ed-9811-4a47-9802-ca21bdd7a626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a21e71-5831-4f73-9fad-e7f38002630e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
