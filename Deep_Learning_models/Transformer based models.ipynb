{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd4084c-4ea0-4264-bf34-03940797fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the IMDB dataset (replace with your dataset path)\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "# Inspect the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Assume the dataset has 'review' and 'sentiment' columns\n",
    "# Convert 'positive' to 1 and 'negative' to 0\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5d9e29-86f1-4e47-8358-01b3f2549dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_19272\\4001921951.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_subset = df.groupby('sentiment', group_keys=False).apply(lambda x: x.sample(subset_size // 2))\n"
     ]
    }
   ],
   "source": [
    "# Sample a subset of 1000 examples (500 positive, 500 negative)\n",
    "subset_size = 1000\n",
    "df_subset = df.groupby('sentiment', group_keys=False).apply(lambda x: x.sample(subset_size // 2))\n",
    "\n",
    "# Save the subset to a new CSV file\n",
    "df_subset.to_csv(\"imdb_subset.csv\", index=False)\n",
    "\n",
    "# Inspect the subset\n",
    "print(df_subset['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b157307-ef92-495c-adce-fd9061bfba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the subset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_subset['review'], df_subset['sentiment'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454656ae-b530-41b8-b22b-fc1ed84d08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training a BERT models\n",
    "\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c929317c-ff58-46b5-af21-cc6f23e59567",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing the data\n",
    "\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        max_length = 128,\n",
    "        padding = \"max_length\",\n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_data(train_texts)\n",
    "test_encodings = tokenize_data(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6dc4b02-a9a3-44bb-a984-51871687bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = IMDBDataset(train_encodings, train_labels)\n",
    "test_dataset = IMDBDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1137b5ce-2f41-4b63-b228-ee264220172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fine tuning the BERT model using Hugging face Trainer\n",
    "\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc8577c0-d270-4eab-b08a-02a3919670d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b5dfa6-de57-4940-82d5-47389567e0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_19272\\4170574626.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 57:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.667800</td>\n",
       "      <td>0.653108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>0.502917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.395518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "0.6859\n",
      "Attempted to log scalar metric grad_norm:\n",
      "6.177656173706055\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.866666666666667e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.2\n",
      "Attempted to log scalar metric loss:\n",
      "0.724\n",
      "Attempted to log scalar metric grad_norm:\n",
      "3.865417003631592\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.7333333333333336e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.4\n",
      "Attempted to log scalar metric loss:\n",
      "0.7005\n",
      "Attempted to log scalar metric grad_norm:\n",
      "5.42045259475708\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.6000000000000003e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.6\n",
      "Attempted to log scalar metric loss:\n",
      "0.6829\n",
      "Attempted to log scalar metric grad_norm:\n",
      "6.729391098022461\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.4666666666666666e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.8\n",
      "Attempted to log scalar metric loss:\n",
      "0.6678\n",
      "Attempted to log scalar metric grad_norm:\n",
      "4.550769329071045\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.3333333333333333e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.6531082987785339\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "61.9254\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "3.23\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "0.404\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n",
      "Attempted to log scalar metric loss:\n",
      "0.6437\n",
      "Attempted to log scalar metric grad_norm:\n",
      "4.552422523498535\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.2e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.2\n",
      "Attempted to log scalar metric loss:\n",
      "0.6343\n",
      "Attempted to log scalar metric grad_norm:\n",
      "5.778733730316162\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.0666666666666667e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.4\n",
      "Attempted to log scalar metric loss:\n",
      "0.611\n",
      "Attempted to log scalar metric grad_norm:\n",
      "4.443190097808838\n",
      "Attempted to log scalar metric learning_rate:\n",
      "9.333333333333334e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "1.6\n",
      "Attempted to log scalar metric loss:\n",
      "0.571\n",
      "Attempted to log scalar metric grad_norm:\n",
      "8.242621421813965\n",
      "Attempted to log scalar metric learning_rate:\n",
      "8.000000000000001e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "1.8\n",
      "Attempted to log scalar metric loss:\n",
      "0.5328\n",
      "Attempted to log scalar metric grad_norm:\n",
      "4.54353666305542\n",
      "Attempted to log scalar metric learning_rate:\n",
      "6.666666666666667e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.0\n",
      "Attempted to log scalar metric eval_loss:\n",
      "0.5029172301292419\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "66.6268\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "3.002\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "0.375\n",
      "Attempted to log scalar metric epoch:\n",
      "2.0\n",
      "Attempted to log scalar metric loss:\n",
      "0.4644\n",
      "Attempted to log scalar metric grad_norm:\n",
      "8.947973251342773\n",
      "Attempted to log scalar metric learning_rate:\n",
      "5.333333333333334e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.2\n",
      "Attempted to log scalar metric loss:\n",
      "0.4036\n",
      "Attempted to log scalar metric grad_norm:\n",
      "6.056611061096191\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.000000000000001e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.4\n",
      "Attempted to log scalar metric loss:\n",
      "0.3787\n",
      "Attempted to log scalar metric grad_norm:\n",
      "5.710477352142334\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.666666666666667e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.6\n",
      "Attempted to log scalar metric loss:\n",
      "0.3358\n",
      "Attempted to log scalar metric grad_norm:\n",
      "5.597777366638184\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.3333333333333334e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.8\n",
      "Attempted to log scalar metric loss:\n",
      "0.3851\n",
      "Attempted to log scalar metric grad_norm:\n",
      "14.86213207244873\n",
      "Attempted to log scalar metric learning_rate:\n",
      "0.0\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_19272\\4170574626.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "0.3955175280570984\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "66.4223\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "3.011\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "0.376\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n",
      "Attempted to log scalar metric train_runtime:\n",
      "3470.6258\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "0.692\n",
      "Attempted to log scalar metric train_steps_per_second:\n",
      "0.043\n",
      "Attempted to log scalar metric total_flos:\n",
      "157866633216000.0\n",
      "Attempted to log scalar metric train_loss:\n",
      "0.5614295546213786\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.5614295546213786, metrics={'train_runtime': 3470.6258, 'train_samples_per_second': 0.692, 'train_steps_per_second': 0.043, 'total_flos': 157866633216000.0, 'train_loss': 0.5614295546213786, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1e611d-c900-4cc0-ba5c-f0b04b820bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\AppData\\Local\\Temp\\ipykernel_19272\\4170574626.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84        96\n",
      "           1       0.87      0.82      0.84       104\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.84      0.84      0.84       200\n",
      "weighted avg       0.84      0.84      0.84       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = torch.argmax(torch.tensor(predictions.predictions), dim=1)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c4c0a4-f01b-40bd-9f7c-8928edea182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./results\\\\tokenizer_config.json',\n",
       " './results\\\\special_tokens_map.json',\n",
       " './results\\\\vocab.txt',\n",
       " './results\\\\added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save_pretrained(\"./results\")\n",
    "tokenizer.save_pretrained(\"./results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d023cd-0bdb-4ea1-acc3-9379158ee76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # No truncation for column values\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "584243db-da10-4193-acbe-72d442d89ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test cases</th>\n",
       "      <th>Negative Probabilities</th>\n",
       "      <th>Positive Probabilities</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow, this movie was just what I needed to cure my insomnia. Absolutely thrilling!</td>\n",
       "      <td>0.450943</td>\n",
       "      <td>0.549057</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best movie ever! I loved wasting 3 hours of my life on this masterpiece.</td>\n",
       "      <td>0.272137</td>\n",
       "      <td>0.727863</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh sure, the acting was so 'natural' I almost believed the actors were wooden dolls.</td>\n",
       "      <td>0.628583</td>\n",
       "      <td>0.371417</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Definitely recommend this movie... if you want to bore yourself to death.</td>\n",
       "      <td>0.606512</td>\n",
       "      <td>0.393488</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The movie was about two friends who embark on a journey. It has a runtime of two hours.</td>\n",
       "      <td>0.425967</td>\n",
       "      <td>0.574033</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It is a typical superhero movie with action scenes and some emotional moments.</td>\n",
       "      <td>0.217186</td>\n",
       "      <td>0.782814</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The cinematography was colorful, and the soundtrack was loud.</td>\n",
       "      <td>0.496208</td>\n",
       "      <td>0.503792</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The second half of the movie was longer than the first.</td>\n",
       "      <td>0.698156</td>\n",
       "      <td>0.301844</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It was okay, I guess, but I wouldn’t watch it again.</td>\n",
       "      <td>0.747976</td>\n",
       "      <td>0.252024</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Not bad, but not great either.</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I laughed, I cried, but I still don’t know if I liked it or not.</td>\n",
       "      <td>0.746268</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The second half was much better than the first, though the ending was questionable.</td>\n",
       "      <td>0.739219</td>\n",
       "      <td>0.260781</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It was very good, super, fantastic.</td>\n",
       "      <td>0.524181</td>\n",
       "      <td>0.475819</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It was good until the second half</td>\n",
       "      <td>0.683074</td>\n",
       "      <td>0.316926</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>It was second half</td>\n",
       "      <td>0.651896</td>\n",
       "      <td>0.348104</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Second half was good</td>\n",
       "      <td>0.616087</td>\n",
       "      <td>0.383913</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Movie is amazing, especially in the Second half</td>\n",
       "      <td>0.296311</td>\n",
       "      <td>0.703689</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Terrible movie, Second half was hilarious</td>\n",
       "      <td>0.841495</td>\n",
       "      <td>0.158505</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>It was okay, Second half was hilarious</td>\n",
       "      <td>0.723998</td>\n",
       "      <td>0.276002</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Best movie if you are looking for a headache</td>\n",
       "      <td>0.682631</td>\n",
       "      <td>0.317369</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lots of fun</td>\n",
       "      <td>0.570644</td>\n",
       "      <td>0.429355</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 Test cases  \\\n",
       "0         Wow, this movie was just what I needed to cure my insomnia. Absolutely thrilling!   \n",
       "1                  Best movie ever! I loved wasting 3 hours of my life on this masterpiece.   \n",
       "2      Oh sure, the acting was so 'natural' I almost believed the actors were wooden dolls.   \n",
       "3                 Definitely recommend this movie... if you want to bore yourself to death.   \n",
       "4   The movie was about two friends who embark on a journey. It has a runtime of two hours.   \n",
       "5            It is a typical superhero movie with action scenes and some emotional moments.   \n",
       "6                             The cinematography was colorful, and the soundtrack was loud.   \n",
       "7                                   The second half of the movie was longer than the first.   \n",
       "8                                      It was okay, I guess, but I wouldn’t watch it again.   \n",
       "9                                                            Not bad, but not great either.   \n",
       "10                         I laughed, I cried, but I still don’t know if I liked it or not.   \n",
       "11      The second half was much better than the first, though the ending was questionable.   \n",
       "12                                                      It was very good, super, fantastic.   \n",
       "13                                                        It was good until the second half   \n",
       "14                                                                       It was second half   \n",
       "15                                                                     Second half was good   \n",
       "16                                          Movie is amazing, especially in the Second half   \n",
       "17                                                Terrible movie, Second half was hilarious   \n",
       "18                                                   It was okay, Second half was hilarious   \n",
       "19                                             Best movie if you are looking for a headache   \n",
       "20                                                                              Lots of fun   \n",
       "\n",
       "    Negative Probabilities  Positive Probabilities Prediction  \n",
       "0                 0.450943                0.549057   Positive  \n",
       "1                 0.272137                0.727863   Positive  \n",
       "2                 0.628583                0.371417   Negative  \n",
       "3                 0.606512                0.393488   Negative  \n",
       "4                 0.425967                0.574033   Positive  \n",
       "5                 0.217186                0.782814   Positive  \n",
       "6                 0.496208                0.503792   Positive  \n",
       "7                 0.698156                0.301844   Negative  \n",
       "8                 0.747976                0.252024   Negative  \n",
       "9                 0.749035                0.250965   Negative  \n",
       "10                0.746268                0.253732   Negative  \n",
       "11                0.739219                0.260781   Negative  \n",
       "12                0.524181                0.475819   Negative  \n",
       "13                0.683074                0.316926   Negative  \n",
       "14                0.651896                0.348104   Negative  \n",
       "15                0.616087                0.383913   Negative  \n",
       "16                0.296311                0.703689   Positive  \n",
       "17                0.841495                0.158505   Negative  \n",
       "18                0.723998                0.276002   Negative  \n",
       "19                0.682631                0.317369   Negative  \n",
       "20                0.570644                0.429355   Negative  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model_path = \"./results\"  # Replace with the directory where your BERT model is saved\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Input reviews\n",
    "new_review_raw = [\n",
    "    \"Wow, this movie was just what I needed to cure my insomnia. Absolutely thrilling!\",\n",
    "    \"Best movie ever! I loved wasting 3 hours of my life on this masterpiece.\",\n",
    "    \"Oh sure, the acting was so 'natural' I almost believed the actors were wooden dolls.\",\n",
    "    \"Definitely recommend this movie... if you want to bore yourself to death.\",\n",
    "    \"The movie was about two friends who embark on a journey. It has a runtime of two hours.\",\n",
    "    \"It is a typical superhero movie with action scenes and some emotional moments.\",\n",
    "    \"The cinematography was colorful, and the soundtrack was loud.\",\n",
    "    \"The second half of the movie was longer than the first.\",\n",
    "    \"It was okay, I guess, but I wouldn’t watch it again.\",\n",
    "    \"Not bad, but not great either.\",\n",
    "    \"I laughed, I cried, but I still don’t know if I liked it or not.\",\n",
    "    \"The second half was much better than the first, though the ending was questionable.\",\n",
    "    \"It was very good, super, fantastic.\",\n",
    "    \"It was good until the second half\",\n",
    "    \"It was second half\",\n",
    "    \"Second half was good\",\n",
    "    \"Movie is amazing, especially in the Second half\",\n",
    "    \"Terrible movie, Second half was hilarious\",\n",
    "    \"It was okay, Second half was hilarious\",\n",
    "    \"Best movie if you are looking for a headache\",\n",
    "    \"Lots of fun\"\n",
    "]\n",
    "\n",
    "# Tokenize the reviews\n",
    "tokenized_inputs = tokenizer(\n",
    "    new_review_raw,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Predict probabilities\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_inputs)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=1).numpy()\n",
    "\n",
    "# Create a DataFrame for results\n",
    "validationResults = pd.DataFrame()\n",
    "validationResults['Test cases'] = new_review_raw\n",
    "validationResults['Negative Probabilities'] = probabilities[:, 0]  # Negative class probabilities\n",
    "validationResults['Positive Probabilities'] = probabilities[:, 1]  # Positive class probabilities\n",
    "\n",
    "# Add predictions based on the threshold\n",
    "validationResults['Prediction'] = np.where(validationResults['Positive Probabilities'] > 0.5, \"Positive\", \"Negative\")\n",
    "\n",
    "# Display the results\n",
    "validationResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dbc0f0-a945-4cbe-ac44-e8f595da8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d02c9-86b5-4d09-af65-a7513346b117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
